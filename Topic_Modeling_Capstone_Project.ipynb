{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Topic_Modeling_Capstone Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malleswarrao/topic_modeling/blob/main/Topic_Modeling_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Extraction/identification of major topics & themes discussed in news articles. </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### In this project your task is to identify major themes/topics across a collection of BBC news articles. You can use clustering algorithms such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA) etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### The dataset contains a set of news articles for each major segment consisting of business, entertainment, politics, sports and technology. You need to create an aggregate dataset of all the news articles and perform topic modeling on this dataset. Verify whether these topics correspond to the different tags available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "81e6c728-92d6-46b6-848f-2124df59fc92",
        "_uuid": "ea84e7b744d0d5701e0019253aa9905718e55d72",
        "id": "Fn5otZjiuYjz"
      },
      "source": [
        "## <b><u> Exploratory Data Analysis </u></b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "import seaborn as sb\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import matplotlib\n",
        "import spacy\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olTcgIGd2czL",
        "outputId": "7f42d73a-4acb-4fb7-d80d-64e0e5a05439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas._libs.lib import maybe_indices_to_slice\n",
        "import csv\n",
        "import glob\n",
        "\n",
        "vals = []\n",
        "main_dataframe = pd.DataFrame()\n",
        "final_df = pd.DataFrame()\n",
        "path = '/content/drive/MyDrive/almabetter/business'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('business')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "\n",
        "path = '/content/drive/MyDrive/almabetter/entertainment'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('entertainment')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "\n",
        "path = '/content/drive/MyDrive/almabetter/politics'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('politics')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "\n",
        "path = '/content/drive/MyDrive/almabetter/sport'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('sport')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "\n",
        "path = '/content/drive/MyDrive/almabetter/tech'\n",
        "\n",
        "files = glob.glob(path + '/*.txt')\n",
        "\n",
        "for i in files:\n",
        "  df1 = pd.read_csv(i, sep=\"/n\",on_bad_lines='skip',encoding= 'unicode_escape')\n",
        "  vals.append('tech')\n",
        "  main_dataframe = pd.concat([main_dataframe, df1], axis = 1)\n",
        "main_dataframe_transposed = main_dataframe.T\n",
        "main_dataframe_copy = main_dataframe_transposed\n",
        "main_dataframe_copy = main_dataframe_copy.reset_index()\n",
        "\n",
        "final_df[0] = main_dataframe_copy['index'].values\n",
        "main_dataframe_copy = main_dataframe_copy.iloc[: , 1:]\n",
        "main_dataframe_copy['new'] = main_dataframe_copy.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "final_df[1]= main_dataframe_copy['new'].values\n",
        "final_df[2]=vals"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVdfOOuY5Dty",
        "outputId": "067d0138-610a-4061-dd22-6f7ef9df52ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   0  \\\n",
            "0  Yukos unit buyer faces loan claim   \n",
            "1  Ad sales boost Time Warner profit   \n",
            "2   Dollar gains on Greenspan speech   \n",
            "3   US trade gap hits record in 2004   \n",
            "4  High fuel prices hit BA's profits   \n",
            "\n",
            "                                                   1         2  \n",
            "0  The owners of embattled Russian oil giant Yuko...  business  \n",
            "1  Quarterly profits at US media giant TimeWarner...  business  \n",
            "2  The dollar has hit its highest level against t...  business  \n",
            "3  The gap between US exports and imports hit an ...  business  \n",
            "4  British Airways has blamed high fuel prices fo...  business  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df=final_df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "gQMy9QPJvasr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[2].value_counts(normalize=True)*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF-ukEz-vhMC",
        "outputId": "d1604837-2377-4ba1-eb5d-3cfae9134e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "business         23.670588\n",
              "sport            23.670588\n",
              "politics         18.964706\n",
              "entertainment    17.364706\n",
              "tech             16.329412\n",
              "Name: 2, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[1] = final_df[1].astype('str') \n"
      ],
      "metadata": {
        "id": "BBLmRgqLvrya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing numbers\n",
        "def remove_numbers(text):\n",
        "\tnumber_pattern = r'\\d+'\n",
        "\twithout_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "\treturn without_number"
      ],
      "metadata": {
        "id": "yMIUkB58v3OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "final_df[1]=final_df[1].apply(remove_numbers)\n"
      ],
      "metadata": {
        "id": "zANywTZGv4hb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}